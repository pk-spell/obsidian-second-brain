# Template – KI-Experiment

> Kopieren/duplizieren für jedes neue KI-Tool-Experiment (z. B. „Claude – Coding-Test“, „Cursor – Web-App-Projekt“).

---

## 1. Meta

- **Datum**: {{YYYY-MM-DD}}
- **Tool**: 
- **Kategorie**: (Web-LLM / CLI / IDE / KI-Browser / Lokal-LLM / Training)
- **Version / Modell**: (z. B. GPT-4.1, Claude 3.5, lokales Modellname)
- **Plattform**: (Browser, VS Code, Cursor, Terminal, macOS, Windows)

---

## 2. Ziel des Experiments

- Was will ich konkret rausfinden?
  - z. B. „Kann dieses Tool mir helfen, eine Flask-App mit Frontend + Backend zu bauen?“
  - z. B. „Wie gut versteht das Tool eine bestehende Terraform-Codebasis?“

---

## 3. Setup

- **Projekt / Repo**:
- **Kontext**:
  - Welche Dateien/Ordner habe ich dem Tool gegeben?
- **Konfiguration**:
  - Prompts, Einstellungen, Limits, evtl. Kontextgrößen.
- **Besondere Rahmenbedingungen**:
  - Offline / Online, lokales Modell vs. Cloud etc.

---

## 4. Testfälle

### 4.1 Testfall 1

- **Beschreibung**: 
- **Prompt / Aufgabe**:
- **Erwartetes Verhalten**:
- **Ergebnis**:
  - ✅ / ❌
  - Kurzbeschreibung:
- **Anmerkungen**:
  - Wo war das Tool stark/schwach?

### 4.2 Testfall 2

- **Beschreibung**:
- **Prompt / Aufgabe**:
- **Ergebnis**:
- **Anmerkungen**:

> Weitere Testfälle einfach kopieren.

---

## 5. Gesamtbewertung

- **Stärken**:
  - …
- **Schwächen**:
  - …
- **Vergleich zu anderen Tools**:
  - vs. ChatGPT:
  - vs. Kimi K2:
  - vs. (falls relevant) andere:

- **Fazit**:
  - Nutze ich dieses Tool weiter?
  - Wenn ja: wofür genau?
  - Wenn nein: warum nicht?

---

## 6. ToDos / Follow-ups

- [ ] Nächster Test mit anderem Usecase?
- [ ] Integration in meinen Workflow (z. B. IDE-Plugin installieren, Alias, Skript)?
- [ ] Doku/Notizen anpassen (`[[KI-Tools-Status]]`, `[[KI-Tooling-Overview]]` updaten).
